Aimybox's HTTP API enables you to connect every platform (voice or text) to your Aimybox's project. For example you can connect any device (not only Android and iOS based) or even a website to your project to enable users speak and chat with your voice project.

# HTTP API Endpoint

The endpoint of Aimybox HTTP API is `https://api.aimybox.com`. Every request to the API should be sent to the one of supported _resources_.

Every request should contain `Content-Type: application/json` header in the case of POST request method.

Every response has a JSON format of the body.

### /request

This resource processes the user's text or voice query through the particular project and returns the response from one of enabled voice skills of this project.

This resource accepts POST requests with the following body template

```
{ 
  "query": "Hello world", 
  "key": "vCfJsokYnKSkZJn4ymvWZwlZs93Wb", 
  "unit": "1568651666267",
  "data": {} 
}
```

**query** - the text of the recognised user's request
**key** - API key of the project
**unit** - unique identifier of the device from where the user sends the request

|| Please note, that in case of using HTTP API you should implement speech recognition and synthesis on your own if you plan to user this API from any device that should interact with user over voice
| You can obtain the API key of your project in your project's settings on app.aimybox.com
| Unit is an arbitrary identifier that should be generated by your system uniquely for every unique device

The response has the following JSON format

```
{
  "query": "2 + 2",
  "text": "4",
  "action": null,
  "intent": "/Calculator/Expression",
  "question": true,
  "data": {},
  "replies": [
    {
      "text": "4",
      "type": "text"
    }
  ]
}
```

**query** contains the original query's text from the request
**text** is a plain text response from one of the enabled skills
**action** is an optional and can contain the device-specified action of the recognised intent
**intent** contains a recognised user's intent
**question** flag defines if the device should continue the conversation with user
**data** JSON object provides additional parameters of the response
**replies** JSON array containing one or more responses from the skill

###### Reply types

Each reply has the type of the reply and additional fields with corresponding data.

[Text reply](/en/article/text-reply-1da2kx7/)
[Image reply](/en/article/image-reply-2mjcyj/)
[Buttons type](/en/article/buttons-type-s4dtzy/)
[Audio reply](/en/article/audio-reply-193a2u0/)

###### Additional data

You can also include **data** field to the JSON body of the API request. This field can contain arbitrary JSON object with any data. This data can be used by any voice skill on the server-side.

For example you can provide current device's coordinates (latitude and longitude). Thus your weather voice skill could obtain the forecast for this place.

|| If you use [Aimylogic webhook](/en/article/aimylogic-webhook-5quhb1/) creating your custom skill, you can access this field through **$rawRequest.data** variable
